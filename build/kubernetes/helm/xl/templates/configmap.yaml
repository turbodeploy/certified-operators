apiVersion: v1
kind: ConfigMap
metadata:
  name: global-properties-{{ .Release.Name }}
  labels:
    app.kubernetes.io/name: {{ .Chart.Name }}
    app.kubernetes.io/instance: {{ .Release.Name }}
    app.kubernetes.io/managed-by: {{ .Release.Service }}
data:
  properties.yaml: |-
    defaultProperties:
      global:
        serverHttpPort : 8080
        serverGrpcPort : 9001
        clustermgr_retry_delay_sec : 10
        kafkaServers : kafka:9092
        kafkaNamespace : {{ .Release.Namespace }}
        deadlockCheckIntervalSecs: 900
        maxHealthyUsedMemoryRatio: 0.95
        scheduledMetricsIntervalMs: 60000
        grpcPingIntervalSeconds: 300
        realtimeTopologyContextId: 777777
        # hostnames for each component type
        actionOrchestratorHost: action-orchestrator
        apiHost: api
        authHost: auth
        consul_host: consul
        consul_port: 8500
        consulNamespace : {{ .Release.Namespace }}
        clusterMgrHost: clustermgr
        clustermgr_port : 8080
        costHost: cost
        dbHost: db
        groupHost: group
        historyHost: history
        marketHost: market
        planOrchestratorHost: plan-orchestrator
        reportingHost: reporting
        repositoryHost: repository
        topologyProcessorHost: topology-processor
        arangoDBNamespace : {{ .Release.Namespace }}
        # Auth
        authRetryDelaySecs: 10
        # Consul Key/Value and Service Discovery Utility
        kvStoreRetryIntervalMillis: 1000
        # Default stat retention times
        retention.numRetainedMinutes: 130
        # DB
        dbPort: 3306
        dbUsername: root
        sqlDialect: MARIADB
        mariadbHealthCheckIntervalSeconds: 60
        # Mediation Component Common
        serverAddress: ws://topology-processor:8080/remoteMediation
        silentRetryTime: 0
        connRetryIntervalSeconds: 10
        # Remote iterator consumers - 10 minutes max wait for next chunk
        com.vmturbo.communication.remote.iterator.timeout: 600000
        # driver property settings must be suitable for inclusion in a URL query
        # string, with individual settings separated by "&". No initial "&" or "?" should appear
        mariadbDriverProperties: useServerPrepStmts=true
        mysqlDriverProperties:
      action-orchestrator:
        identityGeneratorPrefix: 9
        actionPaginationDefaultLimit: 100
        actionPaginationMaxLimit: 500
        actionStatsWriteBatchSize: 500
        dbSchemaName: action
        entityTypeRetryIntervalMillis: 1000
        entityTypeMaxRetries: 6
        maxLiveActionPlanAgeSeconds: 600
        failedGroupUpdateDelaySeconds: 10
        actionStatRollup.corePoolSize: 1
        actionStatRollup.maxPoolSize: 10
        actionStatRollup.threadKeepAliveMins: 1
        actionStatRollup.executorQueueSize: 100
        actionStatCleanup.corePoolSize: 1
        # One thread per table - latest, hourly, daily, monthly
        actionStatCleanup.maxPoolSize: 4
        actionStatCleanup.threadKeepAliveMins: 1
        actionStatCleanup.executorQueueSize: 10
        actionStatCleanup.minTimeBetweenCleanupsMinutes: 60
        retention.updateRetentionIntervalSeconds: 10
        # The length of time after which an In-Progress action should be considered as "failed".
        # Should be long enough to accommodate any long-running actions (e.g. storage move of a huge disk).
        # 6 hrs by default.
        actionExecution.timeoutMins: 360
      api:
        identityGeneratorPrefix: 5
        multipartConfigMaxFileSizeKb: 50
        multipartConfigMaxRequestSizeKb: 200
        targetValidationTimeoutSeconds: 120
        targetValidationPollIntervalSeconds: 2
        targetDiscoveryTimeoutSeconds: 120
        targetDiscoveryPollIntervalSeconds: 2
        liveStatsRetrievalWindowSeconds: 60
        publicVersionString: {{ .Values.global.tag }}
        groupBuildUseCaseFile: groupBuilderUsecases.json
        settingManagersFile: settingManagers.json
        settingStyleFile: settingSpecStyle.json
        initialPlacementTimeoutSeconds: 600
        externalApiSwaggerUri: /vmturbo/apidoc/**
        externalApiFileSystemBase: file:/swagger/
        cpuInfoCacheLifetimeHours: 8
        sessionTimeoutSeconds: 1800
      auth:
        dbSchemaName: auth
        identityGeneratorPrefix: 7
        numBeforeLicenseExpirationDays: 2
      cost:
        identityGeneratorPrefix: 10
        turbonomic.ratecards.persistent.path: /home/turbonomic/data/
        # The normal interval to trigger buy RI analysis after first time run.
        normalBuyRIAnalysisIntervalHours: 336
        # the cost component will receive some large messages over grpc, so we will increase the max
        # message size beyond the 4mb default.
        server.grpcMaxMessageBytes: 12000000
        # DB properties
        dbSchemaName: cost
        persistEntityCostChunkSize: 1000
        # CurrentWeight for calculating the weighted_value in
        # instance_type_hourly_by_week table.
        # Value range from [0.0, 1.0]
        preferredCurrentWeight : 0.6
        # RI buy hour data points value range from 1 to 168 inclusive
        # which is one week of data.
        riMinimumDataPoints : 168
        # Number of records to commit in one batch.
        statsRecordsCommitBatchSize : 5000
        # Number of results to return when fetching lazily.
        statsRecordsQueryBatchSize : 5000
        reservedInstanceStatCleanup.corePoolSize: 1
        # One thread per table - latest, hourly, daily, monthly for RI coverage and utilization
        reservedInstanceStatCleanup.maxPoolSize: 8
        # Schedule for the Reserved Instance tables cleanup scheduler
        reservedInstanceStatCleanup.scheduler: 360000
        retention.updateRetentionIntervalSeconds: 10
        projectedTopologyListenerTimeOut: 3600
      group:
        identityGeneratorPrefix: 4
        createDefaultSettingPolicyRetryIntervalSec: 30
        # make sure the value is the same as in api:sessionTimeoutSeconds
        # TODO: find a better way to sync it with api:sessionTimeoutSeconds
        tempGroupExpirationTimeMins: 30
        dbSchemaName: group_component
      history:
        writeTopologyChunkSize: 1000
        userName: vmtplatform
        requestHost: "%"
        dbSchemaName: vmtdb
        readonlyUserName: vmtreader
        readonlyPassword: vmturbo
        queryTimeoutSeconds: 900
        # Migrations such as adding a new column to an existing huge database can take a
        # long time. So set the timeout to a high value.
        migrationTimeoutSeconds: 86400
        latestTableTimeWindowMin: 15
        historyPaginationDefaultLimit: 100
        historyPaginationMaxLimit: 500
        historyPaginationDefaultSortCommodity: priceIndex
        # note = excluded commodities are case-insensitive, but in mixed case here for readability
        # and to match exactly the values from discovery
        # list obtained from $legacy/com.vmturbo.components.common/src/main/java/com/vmturbo/components/common/ClassicEnumMapper.java
        # The commodities for which stats are not maintained/tracked in the DB.
        # These are typically access commodities.
        excludedCommodities: >-
            ApplicationCommodity
            CLUSTERCommodity
            DATACENTERCommodity
            DATASTORECommodity
            DRSSEGMENTATIONCommodity
            DSPMAccessCommodity
            NETWORKCommodity
            SEGMENTATIONCommodity
            STORAGECLUSTERCommodity
            VAPPAccessCommodity
            VDCCommodity
            VMPMAccessCommodity
        retention.updateRetentionIntervalSeconds: 10
        statsWritersMaxPoolSize: 6
        systemLoadRecordsPerChunk: 500
        timeToWaitNetworkReadinessMs: 10
        # 5-minutes timeout to send big data through GRPC procedure calls
        grpcReadingTimeoutMs: 300000

        # number of BulkInserter batch inserts that can run concurrently
        bulk.parallelBatchInserts: 8
        # default insert batch size
        bulk.batchSize: 1000
        # maximum number of retry attempts for a failed batch insert, before abandoning it as a lost batch
        bulk.maxBatchRetries: 10
        # backoff period before final retry attempt; backoffs for prior retries are computed from this
        bulk.maxRetryBackoffMsec: 60000
        # maximum number of batches that can be submitted for execution at the same time by a single writer
        bulk.maxPendingBatches: 8

        # whether to commit DB operations at chunk boundaries when processing topologies
        ingest.perChunkCommit: false

        # how long to keep processing status in topology coordinator (4 hours = 14400 seconds)
        ingest.topologyStatusRetentionSecs: 14400

        # how long a received topology can sit around waiting to be processed before the listener
        # times out and skips the topology
        ingest.ingestionTimeoutSecs: 1200

        # how long to wait for a snapshot to become eligible for hourly rollup processing, before
        # the associated ingestions are forced into a resolved status to permit the rollups to
        # proceed
        ingest.hourlyRollupTimeoutSecs: 3600

        # how long we can go without repartitioning the stats tables. The longer this doesn't happen,
        # the higher the risk of running out of space on the database server.
        # Normally this happens as a side-effect of daily/monthly rollups, but this is here as a safety
        # valve
        ingest.repartitioningTimeoutSecs: 7200

        # max time processing loop will wait before checking for more work
        ingest.processingLoopMaxSleepSecs: 60

        # default max time allowed for a single writer to process a single chunk
        ingest.defaultChunkTimeLimitMsec: 60000

        # timeouts for various execution "styles" used in HistorydbIO
        # 20 seconds
        executeTimeoutMsec.IMMEDIATE: 20000
        # 1 minute
        executeTimeoutMsec.PATIENT: 60000
        # 2 minutes
        executeTimeoutMsec.FORCED: 120000
      market:
        identityGeneratorPrefix: 2
        # The maximum number of placement iterations the market should perform. Use to prevent ping-ponging VMs from
        # making analysis take too long. If this number is <= 0, uses the default set in the market analysis codebase.
        maxPlacementIterations: -1
        # If entity utilization is below the lower watermark, Market could generate resize down actions.
        rightsizeLowerWatermark: 0.7
        # If entity utilization is above the upper watermark, Market could generate resize up actions.
        rightsizeUpperWatermark: 0.7
        # The maximum ratio of on-demand cost for the new template to current template of a vm for analysis engine to
        # Quote Factor to be used by alleviate pressure plans.
        alleviatePressureQuoteFactor: 0.2
        # Suspension throttling configuration
        suspensionThrottlingPerCluster: true
        # Quote Factor to be used by all analysis runs except for alleviate pressure plans.
        standardQuoteFactor: 0.68
        # Move cost factor for controlling aggressiveness of market in generating on-prem live market move actions.
        liveMarketMoveCostFactor: 0.05
      ml-datastore:
        influxdbHealthCheckIntervalSeconds: 60
        influxHost: influxdb
        influxPort: 8086
        influxUsername: root
        influxDatabaseName: metron
        actionOrchestratorHost: action-orchestrator
        marketHost: market
        # Retain data for 52 weeks (1 year),
        # a replication factor set to one, and a shard group duration set to seven days.
        # For more details on how retention policies work in influxdb see
        # https://www.influxdata.com/blog/influxdb-shards-retention-policies/
        # TODO: At some point consider using continuous queries to do rollups instead of dropping older data.
        # https://docs.influxdata.com/influxdb/v1.7/guides/downsampling_and_retention/
        influxShardDuration: 1w
        influxRetentionPeriod: 52w
        influxRetentionPolicyName: one-year-retention
        # Batch size for writing to influx. The default batch size is 1000
        influxBatchSize: 2000
        gzipToInflux: false
        # Setting jitterEnabled to false OR metricJitter to 0 avoids any jitter.
        jitterEnabled: false
        metricJitter: 0.05
        influxHealthCheckIntervalSeconds: 60
        # Whitelist of commodities to write to influx.
        defaultCommodityWhitelist:
            BALLOONING,
            BUFFER_COMMODITY,
            COLLECTION_TIME,
            CONNECTION,
            COOLING,
            COUPON,
            CPU,
            DB_CACHE_HIT_RATE,
            DB_MEM,
            HEAP,
            HOT_STORAGE,
            IO_THROUGHPUT,
            MEM,
            NET_THROUGHPUT,
            POWER,
            Q1_VCPU,
            Q2_VCPU,
            Q3_VCPU,
            Q4_VCPU,
            Q5_VCPU,
            Q6_VCPU,
            Q7_VCPU,
            Q8_VCPU,
            Q16_VCPU,
            Q32_VCPU,
            Q64_VCPU,
            QN_VCPU,
            RESPONSE_TIME,
            SLA_COMMODITY,
            SPACE,
            STORAGE,
            STORAGE_AMOUNT,
            STORAGE_LATENCY,
            SWAPPING,
            THREADS,
            TRANSACTION,
            TRANSACTION_LOG,
            VCPU,
            VMEM
        # Whitelist of metric types to write to influx.
        defaultMetricTypeWhitelist:
            CAPACITY,
            PEAK,
            SCALING_FACTOR,
            USED
        # Whitelist of action types to write to influx.
        defaultActionTypeWhitelist:
            PROVISION,
            ACTIVATE,
            DEACTIVATE,
            MOVE,
            RESIZE
        # Whitelist of action states to write to influx.
        defaultActionStateWhitelist:
            RECOMMENDED_ACTIONS,
            COMPLETED_ACTIONS
        # Whether we should write cluster membership information as part of our metrics.
        clustersSupported: true
      plan-orchestrator:
        dbSchemaName: plan
        # cron spec for running cluster rollup at 1AM daily = second (0-60) ,minute (0-59), hour(0-23),
        #     day of month(1-31), month(1-12), day of week(0-7, 7=sun)
        clusterRollupSchedule: "0 0 1 * * *"
        # Run plan deletion at 2AM everyday
        planDeletionSchedule: "0 0 2 * * *"
        # Config parameter to control the batch size for deleting old plans.
        planDeletionBatchSize: 500
        # Delay before the next batch of old plans is deleted.
        planDeletionDelayBetweenDeletesSeconds: 120
        identityGeneratorPrefix: 3
        templateSpecFile: defaultTemplateSpec.json
        defaultTemplatesFile: defaultTemplates.json
        # Config parameter to control the time out minutes for running plan.
        planTimeoutMins: 60
        # Time-out for the CPU Info cache; this cache is updated very infrequently.
        cpuInfoCacheLifetimeHours: 8
        # If true, calculate headroom for all clusters in one plan instance.
        # If false, calculate headroom for restricted number of clusters in multiple plan instances.
        headroomCalculationForAllClusters: true
      reporting:
        dbSchemaName: vmtdb
        identityGeneratorPrefix: 8
        scheduledReportsGenerationTime: 1
        maxConnectRetryCount: 60
        retryDelayInMilliSec: 10000
      repository:
        repositorySearchPaginationDefaultLimit: 100
        repositorySearchPaginationMaxLimit: 500
        repositoryEntityStatsPaginationDefaultLimit: 100
        repositoryEntityStatsPaginationMaxLimit: 300
        # Note - OM-36437 - The price index sorting doesn't actually work right now,
        # but there is no other good universally applicable default commodity.
        repositoryEntityStatsPaginationDefaultSortCommodity: priceIndex
        repositoryRealtimeTopologyDropDelaySecs: 30
        numberOfExpectedRealtimeSourceDB: 2
        numberOfExpectedRealtimeProjectedDB: 2
        # we are defaulting to 5 entities per chunk. Serialized entities were in the 1 ~ 5k
        # range in a quick anecdotal test, and this would put the message chunk size at 25 - 125k range.
        # This overlaps reasonably with the rumored optimal message size seems to be 16-64k as per
        # https://github.com/grpc/grpc.github.io/issues/371
        repositoryMaxEntitiesPerChunk: 5
      topology-processor:
        # suppress inspection "UnusedProperty" for whole file
        identityGeneratorPrefix: 1
        # This should be in sync with the schema in the Topology Processor s pom.xml
        dbSchemaName: topology_processor
        activateOrMoveInProgressRecordExpiredSeconds: 3600
        inProgressActionExpiredSeconds: 3600
        moveSucceedRecordExpiredSeconds: 1800
        resizeSucceedRecordExpiredSeconds: 14400
        scaleSucceedRecordExpiredSeconds: 21600
        activateSucceedRecordExpiredSeconds: 14400
        # cloud probe discovery involves downloading some large files, so we are setting the discovery
        # timeout to 120 seconds, instead of using the default of 30 seconds.
        # several keep-alive messages are sent by the client during this interval to keep the connection open.
        discoveryTimeoutSeconds: 120
        validationTimeoutSeconds: 30
        topologyBroadcastIntervalMinutes: 10
        minimumAccountExpensesUploadIntervalMins: 60
        minimumRIDataUploadIntervalMins: 5
        actionTimeoutSeconds: 30
        # Max number of concurrent target discoveries per probe.
        maxConcurrentTargetDiscoveriesPerProbeCount: 5
        # Urgent metrics are collected every 10 minutes, the offline every 3 days
        collectionIntervalUrgentSec: 600
        collectionIntervalOfflineSec: 259200
        anonymized: true
        bridgeHost: clustermgr
        bridgePort: 8120
        discoveredGroupUploadIntervalSeconds: 10
        # Size of chunks for uploading entity settings to the group component
        entitySettingsChunksSize: 100
        # The interval at which to attempt to reload assigned IDs
        # after topology processor startup.
        assignedIdReloadReattemptIntervalSeconds: 10
        # This configuration value controls how often the commodity max values are
        # loaded from history component = 12 Hours
        maxValuesBackgroundLoadFrequencyMinutes: 720
        # Timeout for acquiring the permit for running a discovering operation on a target.
        probeDiscoveryPermitWaitTimeoutMins: 40
        # Additional random interval timeout for acquring permit to prevent thundering herd issue.
        probeDiscoveryPermitWaitTimeoutIntervalMins: 20
        # This configuration value controls the initial delay before triggering
        # the background load task when the initial load during startup fails.
        # For subsequent fetches from the DB or when the initial load succeeds,
        # the delay will be based on the maxValuesBackgroundLoadFrequencyMinutes
        # config value.
        maxValuesBackgroundLoadDelayOnInitFailureMinutes: 30
        # IOPS capacities for each type of disk in Storage Controller, Logical Pool, and Disk Array entities.
        diskIopsCapacitySsd: 5000
        diskIopsCapacity7200Rpm: 800
        diskIopsCapacity10kRpm: 1200
        diskIopsCapacity15kRpm: 1600
        diskIopsCapacityVseriesLun: 5000
        # Factor by which to multiply probe's estimate of array's IOPS capacity
        # For probes like Pure and XtremIO which provide the StorageController
        # and DiskArray estimated IOPS capacity directly rather than a disk count.
        arrayIopsCapacityFactor: 1.0
        # Factors by which to multiply IOPS Capacity if disk has certain properties
        hybridDiskIopsFactor: 1.5
        flashAvailableDiskIopsFactor: 1.3
        # The interval hours that how long the new discovered entities can not be generated
        # resize down actions by Market.
        resizeDownWarmUpIntervalHours: 4
        # Whether or not to periodically collect changes for random entities during stitching
        # in the stitching journal. Use the journal-related parameters below to tune
        # how much information is collected.
        #
        # Even if this parameter is turned to false the journal can be manually collected
        # using the /topology-processor/stitchingJournal REST endpoint.
        stitchingJournalEnabled: true
        # Control parameters for tuning how frequently and how many entities we trace
        # through the stitching journal. Tracking more changes in the journal introduces
        # a greater performance hit but also provides greater debugging information.
        # journalMaxChangesetsPerOperation controls the maximum number of changes to
        # be entered in the journal for a single operation.
        journalMaxChangesetsPerOperation: 100
        # The number of entities that should be chronicled in the journal when we create
        # a non-empty stitching journal. Setting to 0 produces a journal that tracks
        # no changes.
        journalNumEntitiesToRecord: 8
        # In production, in order to ensure the stitching journal has minimal performance impact
        # we usually create an empty journal that does not trace any changes. However, once
        # in every journalsPerRecording, we create a non-empty journal that does trace changes
        # according to the configurations above. So, for example, if journalsPerRecording is 6
        # we will trace stitching changes in one of every 6 broadcasts.
        #
        # To manually trigger the stitching journal at run-time using configurations you
        # can specify (permits custom journal filters and options), use the
        # /topology-processor/stitchingJournal REST endpoint.
        journalsPerRecording: 6
        # Time, in hours that a cpu_model -> scale_factor mapping is cached.
        scaleFactorCacheTimeoutHr: 8
        # Number of full discovery dumps to retain for any given target, unless overridden on a per-target basis
        discoveryDumpsToHold.default: 0
        # The pool size for commodity history values' calculations
        historyAggregationMaxPoolSize: 8
        # The chunk size for fetching data from history component upon startup
        historyAggregationLoadingChunkSize: 1000
        # The chunk size for a task of aggregating commodity history values
        historyAggregationCalculationChunkSize: 2000
        # The percentile buckets distribution per commodity type, should cover the range from 0 to 100.
        # Currently allowed: VCPU VMEM IMAGE_CPU IMAGE_MEM IMAGE_STORAGE
        # If not configured, 101 one-percent buckets will be used.
        #historyAggregation.percentileBuckets.VCPU: 0,1,2,3,4,5,6,7,8,9,10,20,30,40,50,60,70,80,90,91,92,93,84,95,96,97,98,99,100
        # How often to checkpoint the percentile cache in the persistence store
        historyAggregation.percentileMaintenanceWindowHours: 24
        # The maximum message size for serializing percentile blobs
        # Typical size for 10 millions of commodities is 120mb
        historyAggregation.grpcChannelMaxMessageSizeKb: 204800
        # Whether to enable consistent scaling
        consistentScalingEnabled: true
        # How many timeslot-related commodities trigger background history loading vs synchronous
        historyAggregation.backgroundLoadingThreshold: 5000
        # How many background history loading retries are tolerated before stopping and sending up a notification
        historyAggregation.backgroundLoadingRetries: 3
        # How long a single background loading attempt is allowed to take before failing
        historyAggregation.backgroundLoadingTimeoutMin: 60
        # How often to expire the timeslot cached data going out of observation window
        historyAggregation.timeslotMaintenanceWindowHours: 23
        fullAzureEARIDiscovery: false
{{- if .Values.properties }}
    customProperties:
{{ toYaml .Values.properties | indent 12 }}
{{- end }}
