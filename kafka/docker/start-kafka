#!/bin/bash

# If LOG_TO_STDOUT is defined in the environment, tee the output so that it is also logged to stdout.
# This is generally desirable in a development setup where you want to see the output on the console when
# starting a component, but not in production where we do not want logging to be captured by Docker
# and consume disk space (Docker JSON log driver captures and saves them then docker logs shows them).
# In a production environment, get the logs from the rsyslog component instead.
if [[ -z ${LOG_TO_STDOUT} ]]; then
  export LOGGER_COMMAND="logger --tag kafka-${BROKER_ID} -u /tmp/log.sock"
else
  export LOGGER_COMMAND="eval tee >(logger --tag kafka-${BROKER_ID} -u /tmp/log.sock)"
fi

start_kafka() {
    kafka_bin=/opt/kafka/bin/kafka-server-start.sh

    kafka_server_config=/opt/kafka/config/server.properties

    #export KAFKA_OPTS="-Djava.net.preferIPv4Stack=true"

    env

    if [ -n "$CURRENT_KAFKA_VERSION" ]; then
        KAFKA_PARAMS="$KAFKA_PARAMS --override inter.broker.protocol.version=$CURRENT_KAFKA_VERSION"
    fi

    if [ -n "$CURRENT_MESSAGE_FORMAT_VERSION" ]; then
        KAFKA_PARAMS="$KAFKA_PARAMS --override log.message.format.version=$CURRENT_MESSAGE_FORMAT_VERSION"
    fi

    KAFKA_PARAMS="$KAFKA_PARAMS --override broker.id=$BROKER_ID"
    KAFKA_PARAMS="$KAFKA_PARAMS --override zookeeper.connect=$ZOOKEEPER_HOSTS"
    KAFKA_PARAMS="$KAFKA_PARAMS --override listeners=PLAINTEXT://:$ADVERTISED_PORT"

    echo Executing kafka with options: $KAFKA_PARAMS

    # disable GC logging in order, as we do not have any space to write it.
    export KAFKA_GC_LOG_OPTS=" "

    $kafka_bin $kafka_server_config $KAFKA_PARAMS
}

/usr/sbin/rsyslogd -f /etc/rsyslog.conf -i /tmp/rsyslog.pid

start_kafka | $LOGGER_COMMAND
