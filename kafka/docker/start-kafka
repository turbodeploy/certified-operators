#!/bin/bash

# If LOG_TO_STDOUT is defined in the environment, tee the output so that it is also logged to stdout.
# This is generally desirable in a development setup where you want to see the output on the console when
# starting a component, but not in production where we do not want logging to be captured by Docker
# and consume disk space (Docker JSON log driver captures and saves them then docker logs shows them).
# In a production environment, get the logs from the rsyslog component instead.
. /etc/kafka.profile

if [[ -z ${LOG_TO_STDOUT} ]]; then
  export LOGGER_COMMAND="logger --tag kafka-${BROKER_ID} -u /tmp/log.sock"
else
  export LOGGER_COMMAND="eval tee >(logger --tag kafka-${BROKER_ID} -u /tmp/log.sock)"
fi

kafka_bin=/opt/kafka/bin/kafka-server-start.sh

/usr/sbin/rsyslogd -f /etc/rsyslog.conf -i /tmp/rsyslog.pid

if [ -n "$CURRENT_KAFKA_VERSION" ]; then
    KAFKA_PARAMS="$KAFKA_PARAMS --override inter.broker.protocol.version=$CURRENT_KAFKA_VERSION"
fi

if [ -n "$CURRENT_MESSAGE_FORMAT_VERSION" ]; then
    KAFKA_PARAMS="$KAFKA_PARAMS --override log.message.format.version=$CURRENT_MESSAGE_FORMAT_VERSION"
fi

KAFKA_PARAMS="$KAFKA_PARAMS --override broker.id=$BROKER_ID"
KAFKA_PARAMS="$KAFKA_PARAMS --override zookeeper.connect=$ZOOKEEPER_HOSTS"
KAFKA_PARAMS="$KAFKA_PARAMS --override log.dirs=$KAFKA_DATA_DIR"
# set up configuration for an INTERNAL listener and an EXTERNAL listener. clients connecting on the
# INTERNAL port will be mapped to internally-resolvable (i.e. inside the docker network) broker
# addresses, while clients connecting to the EXTERNAL port will be mapped to externally (outside
# the docker network) accessible broker addresses.
# For more info, see
#   https://cwiki.apache.org/confluence/display/KAFKA/KIP-103%3A+Separation+of+Internal+and+External+traffic

KAFKA_PARAMS="$KAFKA_PARAMS --override inter.broker.listener.name=INTERNAL"

# mTLS credential file injected from K8S secret.
mtlsfile='/vault/mtlsSecrets/mtls-creds'

TLS_KEYSTORE="TLS_KEYSTORE"
TLS_KEYSTORE_PASS="TLS_KEYSTORE_PASS"
TLS_KEY_PASS="TLS_KEY_PASS"
TLS_TRUSTSTORE="TLS_TRUSTSTORE"
TLS_TRUSTSTORE_PASS="TLS_TRUSTSTORE_PASS"

# Read mTLS credential file
# [[:blank:]] is a POSIX regex class (remove spaces, tabs...), see http://www.regular-expressions.info/posixbrackets.html
# <(grep ""  is a solution to the 'no terminal newline' problem
while IFS=: read -r key value; do
    if [ "$key" = "$TLS_KEYSTORE" ]; then
        KAFKA_TLS_KEYSTORE="${value//[[:blank:]]/}"
    elif [ "$key" = "$TLS_KEYSTORE_PASS" ]; then
        KAFKA_TLS_KEYSTORE_PASS="${value//[[:blank:]]/}"
    elif [ "$key" = "$TLS_KEY_PASS" ]; then
        KAFKA_TLS_KEY_PASS="${value//[[:blank:]]/}"
    elif [ "$key" = "$TLS_TRUSTSTORE" ]; then
        KAFKA_TLS_TRUSTSTORE="${value//[[:blank:]]/}"
    elif [ "$key" = "$TLS_TRUSTSTORE_PASS" ]; then
        KAFKA_TLS_TRUSTSTORE_PASS="${value//[[:blank:]]/}"
    else
        echo "Unknown key and value:"
        echo "$key"
    fi
done <  <(grep "" "$mtlsfile")

if [ "$KAFKA_TLS_ENABLED" = "true" ] && [ -n "$KAFKA_TLS_KEYSTORE" ] && [ -n "$KAFKA_TLS_KEYSTORE_PASS" ] && [ -n "$KAFKA_TLS_KEY_PASS" ] && [ -n "$KAFKA_TLS_TRUSTSTORE" ] && [ -n "$KAFKA_TLS_TRUSTSTORE_PASS" ]; then
    # add configuration for mTLS
    KAFKA_PARAMS="$KAFKA_PARAMS --override ssl.keystore.location=$KAFKA_TLS_KEYSTORE"
    KAFKA_PARAMS="$KAFKA_PARAMS --override ssl.keystore.password=$KAFKA_TLS_KEYSTORE_PASS"
    KAFKA_PARAMS="$KAFKA_PARAMS --override ssl.key.password=$KAFKA_TLS_KEY_PASS"
    KAFKA_PARAMS="$KAFKA_PARAMS --override ssl.truststore.location=$KAFKA_TLS_TRUSTSTORE"
    KAFKA_PARAMS="$KAFKA_PARAMS --override ssl.truststore.password=$KAFKA_TLS_TRUSTSTORE_PASS"

    # add TLS protocol, default to TLS 1.2
    if [ -n "$KAFKA_TLS_ENABLED_PROTOCOLS" ]; then
      KAFKA_PARAMS="$KAFKA_PARAMS --override ssl.enabled.protocols=$KAFKA_TLS_ENABLED_PROTOCOLS"
    else
      KAFKA_PARAMS="$KAFKA_PARAMS --override ssl.enabled.protocols=TLSv1.2"
    fi

    # Customized socket request max byte for TLS. Prevent InvalidReceiveException: Invalid receive (size = 369296129 larger than 104857600)
    if [ -n "$KAFKA_SOCKET_REQUEST_MAX_BYTE" ]; then
      KAFKA_PARAMS="$KAFKA_PARAMS --override socket.request.max.bytes=$KAFKA_SOCKET_REQUEST_MAX_BYTE"
    else
      KAFKA_PARAMS="$KAFKA_PARAMS --override socket.request.max.bytes=370296129"
    fi

    KAFKA_PARAMS="$KAFKA_PARAMS --override ssl.enabled.protocols=$KAFKA_TLS_ENABLED_PROTOCOLS"
    KAFKA_PARAMS="$KAFKA_PARAMS --override listener.security.protocol.map=PLAINTEXT:PLAINTEXT,INTERNAL:SSL,EXTERNAL:PLAINTEXT"
else
    KAFKA_PARAMS="$KAFKA_PARAMS --override listener.security.protocol.map=PLAINTEXT:PLAINTEXT,INTERNAL:PLAINTEXT,EXTERNAL:PLAINTEXT"
fi

if [ -n "$KAFKA_EXTERNAL_BROKER_ADDRESS" ] && [ -n "$KAFKA_EXTERNAL_PORT" ]; then
    # add configuration for supporting both internal and external access
    KAFKA_PARAMS="$KAFKA_PARAMS --override listeners=INTERNAL://0.0.0.0:$KAFKA_INTERNAL_PORT,EXTERNAL://0.0.0.0:$KAFKA_EXTERNAL_PORT"
    KAFKA_PARAMS="$KAFKA_PARAMS --override advertised.listeners=INTERNAL://$KAFKA_INTERNAL_BROKER_ADDRESS:$KAFKA_INTERNAL_PORT,EXTERNAL://$KAFKA_EXTERNAL_BROKER_ADDRESS:$KAFKA_EXTERNAL_PORT"
else
    # default: only listen internally
    # KAFKA_PARAMS="$KAFKA_PARAMS --override listeners=PLAINTEXT://:$KAFKA_INTERNAL_PORT"
    KAFKA_PARAMS="$KAFKA_PARAMS --override listeners=INTERNAL://:$KAFKA_INTERNAL_PORT"
fi

if [ -z "$KAFKA_ZOOKEEPER_SESSION_TIMEOUT_MS" ]; then
    # we'll default zookeeper timeout to 18 seconds now, which is also the new default in kafka 2.5.0+
    KAFKA_ZOOKEEPER_SESSION_TIMEOUT_MS="18000"
fi

# Set a default retention period to 24 hours for now. TODO: refine this setting per-topic based
# our topic-specific needs.
KAFKA_PARAMS="$KAFKA_PARAMS --override log.retention.hours=$KAFKA_LOG_RETENTION_HRS"
# set the max.message.bytes for the whole server, until we can tune this with more granularity
KAFKA_PARAMS="$KAFKA_PARAMS --override message.max.bytes=$KAFKA_MAX_MESSAGE_BYTES"
# set the broker default message timestamp type
KAFKA_PARAMS="$KAFKA_PARAMS --override log.message.timestamp.type=LogAppendTime"
# override the zookeeper session timeout. This should help us with noisy / resource-congested environments.
KAFKA_PARAMS="$KAFKA_PARAMS --override zookeeper.session.timeout.ms=$KAFKA_ZOOKEEPER_SESSION_TIMEOUT_MS"

# turn off auto-created topics
KAFKA_PARAMS="$KAFKA_PARAMS --override auto.create.topics.enable=false"

echo Executing kafka with options: $KAFKA_PARAMS | $LOGGER_COMMAND

# disable GC logging in order, as we do not have any space to write it.
export KAFKA_GC_LOG_OPTS=" "

# move out the old data directory if exist
if [ -d /home/kafka/data/data ]; then
  mv /home/kafka/data/data /home/kafka/data.old
fi

exec $kafka_bin $KAFKA_SERVER_CONFIG $KAFKA_PARAMS > >($LOGGER_COMMAND) 2>&1

