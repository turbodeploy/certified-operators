package com.vmturbo.cloud.commitment.analysis.runtime.stages.recommendation;

import java.time.Duration;
import java.time.Instant;
import java.util.ArrayList;
import java.util.Collection;
import java.util.Collections;
import java.util.List;
import java.util.Map;
import java.util.Objects;
import java.util.Set;
import java.util.concurrent.ExecutionException;
import java.util.concurrent.ExecutorCompletionService;
import java.util.concurrent.Future;
import java.util.concurrent.TimeUnit;
import java.util.function.Function;
import java.util.stream.Collectors;

import javax.annotation.Nonnull;

import com.google.common.base.Stopwatch;
import com.google.common.collect.ImmutableList;
import com.google.common.collect.ImmutableMap;
import com.google.common.collect.ImmutableSet;
import com.google.common.collect.ImmutableSetMultimap;

import org.apache.commons.lang3.tuple.Pair;
import org.apache.logging.log4j.LogManager;
import org.apache.logging.log4j.Logger;

import com.vmturbo.cloud.commitment.analysis.demand.ScopedCloudTierInfo;
import com.vmturbo.cloud.commitment.analysis.pricing.RateAnnotatedCommitmentContext;
import com.vmturbo.cloud.commitment.analysis.runtime.AnalysisStage;
import com.vmturbo.cloud.commitment.analysis.runtime.CloudCommitmentAnalysisContext;
import com.vmturbo.cloud.commitment.analysis.runtime.stages.AbstractStage;
import com.vmturbo.cloud.commitment.analysis.runtime.stages.pricing.PricingResolverOutput;
import com.vmturbo.cloud.commitment.analysis.runtime.stages.recommendation.RecommendationAnalysisTask.RecommendationAnalysisTaskFactory;
import com.vmturbo.cloud.commitment.analysis.runtime.stages.recommendation.RecommendationTopology.RecommendationDemandSegment;
import com.vmturbo.cloud.commitment.analysis.runtime.stages.transformation.AggregateCloudTierDemand;
import com.vmturbo.common.protobuf.cca.CloudCommitmentAnalysis.CloudCommitmentAnalysisConfig;
import com.vmturbo.common.protobuf.cca.CloudCommitmentAnalysis.CommitmentPurchaseProfile;

/**
 * This stage is responsible for generating cloud commitment recommendations, through the savings
 * calculator. The output of this stage is the set of recommendations for the analysis.
 */
public class RecommendationAnalysisStage extends AbstractStage<PricingResolverOutput, CloudCommitmentRecommendations> {

    private static final String STAGE_NAME = "Recommendation Analysis";

    private final Logger logger = LogManager.getLogger();

    private final RecommendationAnalysisTaskFactory recommendationAnalysisTaskFactory;

    private final Duration recommendationTaskSummaryInterval;

    private RecommendationAnalysisStage(final long id,
                                        @Nonnull final CloudCommitmentAnalysisConfig analysisConfig,
                                        @Nonnull final CloudCommitmentAnalysisContext analysisContext,
                                        @Nonnull RecommendationAnalysisTaskFactory recommendationAnalysisTaskFactory,
                                        @Nonnull Duration recommendationTaskSummaryInterval) {
        super(id, analysisConfig, analysisContext);

        this.recommendationAnalysisTaskFactory = Objects.requireNonNull(recommendationAnalysisTaskFactory);
        this.recommendationTaskSummaryInterval = Objects.requireNonNull(recommendationTaskSummaryInterval);
    }

    /**
     * Executes the recommendation analysis, through {@link RecommendationAnalysisTask} instances (representing
     * a single purchase candidate).
     * @param rateAnnotatedTopology The analysis topology, with demand annotated with the rates to use for
     *                              the analysis.
     * @return The set of recommendations generated by the analysis.
     * @throws Exception An unrecoverable exception.
     */
    @Nonnull
    @Override
    public StageResult<CloudCommitmentRecommendations> execute(final PricingResolverOutput rateAnnotatedTopology) throws Exception {

        final List<RecommendationAnalysisTask> recommendationTasks = createRecommendationTasks(rateAnnotatedTopology);
        final List<CloudCommitmentRecommendation> commitmentRecommendations = executeRecommendationTasks(recommendationTasks);

        return StageResult.<CloudCommitmentRecommendations>builder()
                .output(CloudCommitmentRecommendations.builder()
                        .analysisTopology(rateAnnotatedTopology.analysisTopology())
                        .commitmentRecommendations(commitmentRecommendations)
                        .build())
                .resultSummary(RecommendationSummary.generateSummary(
                        analysisContext.getSourceCloudTopology(),
                        commitmentRecommendations))
                .build();
    }

    /**
     * Creates the recommendation tasks. Each recommendation task maps to a single recommendation
     * candidate.
     * @param rateAnnotatedTopology The analysis topology.
     * @return The immutable list of recommendation tasks.
     */
    private List<RecommendationAnalysisTask> createRecommendationTasks(PricingResolverOutput rateAnnotatedTopology) {

        final CommitmentPurchaseProfile purchaseProfile = analysisConfig.getPurchaseProfile();
        final List<RecommendationTopology> recommendationTopologies =
                createRecommendationTopologies(rateAnnotatedTopology);

        return recommendationTopologies.stream()
                .map(recommendationTopology -> recommendationAnalysisTaskFactory.newTask(
                        recommendationTopology,
                        analysisContext.getComputeTierFamilyResolver(),
                        purchaseProfile))
                .collect(ImmutableList.toImmutableList());

    }

    private List<CloudCommitmentRecommendation> executeRecommendationTasks(
            @Nonnull Collection<RecommendationAnalysisTask> recommendationTasks) throws ExecutionException, InterruptedException {

        final List<CloudCommitmentRecommendation> recommendationResults = new ArrayList<>();

        final ExecutorCompletionService<CloudCommitmentRecommendation> completionService =
                new ExecutorCompletionService(analysisContext.getAnalysisExecutorService());

        recommendationTasks.forEach(completionService::submit);

        final Stopwatch aggregateTime = Stopwatch.createStarted();

        int tasksSize = recommendationTasks.size();
        Instant summaryTime = Instant.now().plus(recommendationTaskSummaryInterval);
        while (recommendationResults.size() < tasksSize) {

            final Duration timeToSummary = Duration.between(Instant.now(), summaryTime);
            if (timeToSummary.isNegative() || timeToSummary.isZero()) {
                logger.info("Recommendation analysis task summary (Completed={}, Total={})",
                        recommendationResults.size(), tasksSize);

                summaryTime = Instant.now().plus(recommendationTaskSummaryInterval);
            } else {
                try {
                    final Future<CloudCommitmentRecommendation> resultFuture =
                            completionService.poll(timeToSummary.toNanos(), TimeUnit.NANOSECONDS);
                    if (resultFuture != null) {
                        final CloudCommitmentRecommendation commitmentRecommendation = resultFuture.get();
                        recommendationResults.add(commitmentRecommendation);
                        logger.debug("Recommendation analysis task completed (Analysis Time Interval={})");
                    } // else repeat
                } catch (ExecutionException e) {
                    // If a single recommendation fails, log the error, but allow other tasks
                    // to proceed.
                    logger.error("Error executing recommendation analysis task", e);
                    tasksSize--;
                }
            }
        }

        logger.info("Coverage calculation completed (Total segments={}, Aggregate time={})",
                tasksSize, aggregateTime);
        return recommendationResults;
    }

    private Collection<Set<ScopedCloudTierInfo>> groupRecommendationsByOrg(Set<ScopedCloudTierInfo> cloudTierInfoSet) {
        return cloudTierInfoSet.stream()
                .collect(Collectors.groupingBy(
                        (cloudTierInfo -> cloudTierInfo.billingFamilyId()
                                .orElse(cloudTierInfo.accountOid())),
                        Collectors.toSet()))
                .values();
    }

    /**
     * This method is responsible for scoping the analysis topology to each individual recommendation
     * candidate through a {@link RecommendationTopology}. This allows the savings calculator and
     * recommendation task to assume all demand in the recommendation topology is relevant to the
     * recommendation candidate.
     * @param rateAnnotatedTopology The source analysis topology.
     * @return A list of {@link RecommendationTopology} instances, corresponding to {@link RateAnnotatedCommitmentContext}
     * instances within {@code rateAnnotatedTopology}.
     */
    private List<RecommendationTopology> createRecommendationTopologies(@Nonnull PricingResolverOutput rateAnnotatedTopology) {

        final Stopwatch stopwatch = Stopwatch.createStarted();

        final Map<ScopedCloudTierInfo, RecommendationTopology.Builder> topologyBuildersByScope =
                rateAnnotatedTopology.rateAnnotatedCommitmentContextSet().stream()
                        .flatMap(commitmentContext -> {
                            final Set<ScopedCloudTierInfo> cloudTierInfoSet =
                                    commitmentContext.cloudTierPricingByScope().keySet();

                            // Group the applicable cloud tiers by org. A t2.nano spec may match
                            // to two scoped cloud tiers in separate billing families, which should
                            // be split into separate recommendation topologies, leading to separate
                            // analyses and recommendations.
                            return groupRecommendationsByOrg(cloudTierInfoSet).stream()
                                    .flatMap(groupedCloudTierSet -> {
                                        final RecommendationTopology.Builder topologyBuilder = RecommendationTopology.builder()
                                                .commitmentContext(commitmentContext);

                                        return groupedCloudTierSet.stream()
                                                .map(cloudTierInfo -> Pair.of(cloudTierInfo, topologyBuilder));
                                    });
                        }).collect(ImmutableMap.toImmutableMap(
                                Pair::getKey,
                                Pair::getValue));

        final Set<RecommendationTopology.Builder> topologyBuilders = ImmutableSet.copyOf(topologyBuildersByScope.values());
        rateAnnotatedTopology.analysisTopology().segments().forEach(analysisSegment -> {
            final Map<RecommendationTopology.Builder, Set<AggregateCloudTierDemand>> demandByTopologyBuilder =
                    analysisSegment.aggregateCloudTierDemandSet().values()
                            .stream()
                            .filter(AggregateCloudTierDemand::isRecommendationCandidate)
                            // Some demand will not be associated with a context, if pricing for the demand
                            // could not be found.
                            .filter(aggregateDemand -> topologyBuildersByScope.containsKey(aggregateDemand.cloudTierInfo()))
                            .collect(Collectors.groupingByConcurrent(
                                    demand -> topologyBuildersByScope.get(demand.cloudTierInfo()),
                                    Collectors.toSet()));

            // go through all topology builder - if there is no demand, insert an empty demand segment
            topologyBuilders.forEach(topologyBuilder -> {
                final Set<AggregateCloudTierDemand> demandSet =
                        demandByTopologyBuilder.getOrDefault(topologyBuilder, Collections.emptySet());
                topologyBuilder.addDemandSegment(RecommendationDemandSegment.builder()
                        .timeInterval(analysisSegment.timeInterval())
                        .putAllAggregateCloudTierDemandSet(
                                demandSet.stream()
                                        .collect(ImmutableSetMultimap.toImmutableSetMultimap(
                                                AggregateCloudTierDemand::cloudTierInfo,
                                                Function.identity())))
                        .build());
            });
        });

        logger.info("Topology iteration for recommendation topologies complete (Stopwatch={})", stopwatch);
        return topologyBuilders.stream()
                .map(RecommendationTopology.Builder::build)
                // Return as a list - no need to compare and de-dupe.
                .collect(ImmutableList.toImmutableList());
    }

    /**
     * {@inheritDoc}.
     */
    @Nonnull
    @Override
    public String stageName() {
        return STAGE_NAME;
    }

    /**
     * A factory class for creating {@link RecommendationAnalysisStage} instances.
     */
    public static class RecommendationAnalysisFactory implements
            AnalysisStage.StageFactory<PricingResolverOutput, CloudCommitmentRecommendations> {

        private final RecommendationAnalysisTaskFactory recommendationAnalysisTaskFactory;

        private final Duration recommendationTaskSummaryInterval;

        /**
         * Constructs a new factory instance.
         * @param recommendationAnalysisTaskFactory The analysis task factory.
         * @param recommendationTaskSummaryInterval The interval at which the status of the analysis
         *                                          tasks should be logged.
         */
        public RecommendationAnalysisFactory(@Nonnull RecommendationAnalysisTaskFactory recommendationAnalysisTaskFactory,
                                             @Nonnull Duration recommendationTaskSummaryInterval) {

            this.recommendationAnalysisTaskFactory = Objects.requireNonNull(recommendationAnalysisTaskFactory);
            this.recommendationTaskSummaryInterval = Objects.requireNonNull(recommendationTaskSummaryInterval);
        }

        /**
         *  Constructs a new {@link RecommendationAnalysisStage} instance.
         * @param id The unique ID of the stage.
         * @param config The configuration of the analysis.
         * @param context The context of the analysis, used to share context data across stages
         * @return The newly constructed {@link RecommendationAnalysisStage} instance.
         */
        @Nonnull
        @Override
        public AnalysisStage<PricingResolverOutput, CloudCommitmentRecommendations> createStage(
                final long id,
                @Nonnull final CloudCommitmentAnalysisConfig config,
                @Nonnull final CloudCommitmentAnalysisContext context) {

            return new RecommendationAnalysisStage(
                    id,
                    config,
                    context,
                    recommendationAnalysisTaskFactory,
                    recommendationTaskSummaryInterval);
        }
    }
}
