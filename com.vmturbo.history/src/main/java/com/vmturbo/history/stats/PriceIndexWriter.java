package com.vmturbo.history.stats;

import java.time.Duration;
import java.time.Instant;
import java.util.ArrayList;
import java.util.List;
import java.util.Map;
import java.util.Map.Entry;
import java.util.Optional;
import java.util.Set;

import javax.annotation.Nonnull;

import org.apache.commons.collections4.CollectionUtils;
import org.apache.logging.log4j.LogManager;
import org.apache.logging.log4j.Logger;
import org.jooq.InsertSetMoreStep;
import org.jooq.Query;
import org.jooq.Table;

import com.google.common.collect.Iterables;
import com.google.common.collect.Lists;
import com.google.common.collect.Sets;

import com.vmturbo.common.protobuf.topology.TopologyDTO;
import com.vmturbo.history.SharedMetrics;
import com.vmturbo.history.db.BasedbIO;
import com.vmturbo.history.db.HistorydbIO;
import com.vmturbo.history.db.VmtDbException;
import com.vmturbo.history.schema.RelationType;
import com.vmturbo.components.common.utils.StringConstants;
import com.vmturbo.history.topology.TopologySnapshotRegistry;
import com.vmturbo.history.utils.TopologyOrganizer;
import com.vmturbo.platform.analysis.protobuf.PriceIndexDTOs;

/**
 * Write stats derived from a PriceIndex message to the RDB.
 */
public class PriceIndexWriter {
    private static final double DEFAULT_PRICE_IDX = 1.0;

    private static final Logger logger = LogManager.getLogger();

    private final HistorydbIO historydbIO;

    // the number of entities for which stats are persisted in a single DB Insert operations
    private final int writeTopologyChunkSize;

    /**
     * a utility class to coordinate async receipt of Topology and PriceIndex messages for the
     * same topologyContext.
     */
    private final TopologySnapshotRegistry snapshotRegistry;


    public PriceIndexWriter(TopologySnapshotRegistry topologySnapshotRegistry,
                            HistorydbIO historydbIO, int writeTopologyChunkSize) {
        this.historydbIO = historydbIO;
        this.snapshotRegistry = topologySnapshotRegistry;
        this.writeTopologyChunkSize = writeTopologyChunkSize;
    }

    /**
     * Persist priceIndex values to the DB, once the corresponding topology has been received.
     * The {@link TopologySnapshotRegistry} tracks the two components, managing the async
     * delivery.
     *
     * @param topologyContextId the long-running topology context to which this priceIndex info
     *                          belongs
     * @param topologyId        id for this specific topology
     * @param priceIndexByEntity A map from entity ID to the price index for the entity.
     */
    public void persistPriceIndexInfo(final long topologyContextId,
                                      final long topologyId,
                                      @Nonnull final Map<Long, Double> priceIndexByEntity) {
        // use the snapshotRegistry to sequence the processing, ensuring the topology is
        // processed before the priceIndex
        snapshotRegistry.registerPriceIndexInfo(topologyContextId, topologyId, topologyOrganizer -> {
            // this block will run when the full topology is available; might already be, but
            // ... might not yet be
            logger.debug("persisting live priceIndex, contextId: {}, topo: {}, items: {}",
                    topologyContextId, topologyId, priceIndexByEntity.size());
            SharedMetrics.UPDATE_PRICE_INDEX_DURATION_SUMMARY
                    .labels(SharedMetrics.LIVE_CONTEXT_TYPE_LABEL)
                    .time(() -> persistPriceIndexInfoInternal(priceIndexByEntity, topologyOrganizer));
        });
    }

    /**
     * Persist "priceIndex" info, generated by the Market, to the _stats_latest database
     * for each entity in the payloadList.
     * <p>
     * <p><p>The records are inserted, nothing is updated, and so we rely on "auto-commit" for each
     * operation.
     * <p>
     * <p><p>The connection will auto-close.
     * <p>
     * <p>The database is determined based on the Entity Type, so we use the snapshotRegistry to
     * provide that information.
     *
     * @param priceIndexByEntity the priceIndex information to persist - entityId -> priceIndex
     * @param topologyOrganizer     the snapshot map  used to look up {@link TopologyDTO.TopologyEntityDTO} by oid
     */
    private void persistPriceIndexInfoInternal(@Nonnull final Map<Long, Double> priceIndexByEntity,
                                       TopologyOrganizer topologyOrganizer) {
        logger.debug("Persisting priceIndex info for context: {}, topology: {}, count: {}",
                topologyOrganizer.getTopologyContextId(),
                topologyOrganizer.getTopologyId(),
                priceIndexByEntity.size());
        Instant start = Instant.now();
        try {

            // accumulate a batch of SQL statements to insert the commodity rows; execute in batches
            List<Query> commodityInsertStatements = Lists.newArrayList();

            final Set<Long> missingEntityOids = Sets.newHashSet();

            // We want to write price index
            for (final Entry<Long, Double> idAndPriceIdx : priceIndexByEntity.entrySet()) {
                final Optional<Integer> entityTypeId = topologyOrganizer.getEntityType(idAndPriceIdx.getKey());
                if (!entityTypeId.isPresent()) {
                    missingEntityOids.add(idAndPriceIdx.getKey());
                } else {
                    final long snapshotTime = topologyOrganizer.getSnapshotTime();
                    final Table<?> dbTable = historydbIO.getLatestDbTableForEntityType(entityTypeId.get());
                    if (dbTable != null) {
                        final InsertSetMoreStep<?> insertStmt = historydbIO.getCommodityInsertStatement(dbTable);
                        historydbIO.initializeCommodityInsert(StringConstants.PRICE_INDEX, snapshotTime,
                                idAndPriceIdx.getKey(), RelationType.METRICS, null, null, null,
                                null, insertStmt, dbTable);
                        // set the values specific to used component of commodity and write
                        historydbIO.setCommodityValues(StringConstants.PRICE_INDEX, idAndPriceIdx.getValue(),
                                insertStmt, dbTable);
                        commodityInsertStatements.add(insertStmt);
                        if (commodityInsertStatements.size() > writeTopologyChunkSize) {
                            // execute a batch of updates - FORCED implies repeat until successful
                            historydbIO.execute(BasedbIO.Style.FORCED, commodityInsertStatements);
                            commodityInsertStatements = new ArrayList<>(writeTopologyChunkSize);
                        }
                    }
                }
            }

            if (missingEntityOids.size() > 0) {
                logger.warn("missing entity DTOs from topology context {};  " +
                                "topology ID {};  skipping {}",
                        topologyOrganizer.getTopologyContextId(),
                        topologyOrganizer.getTopologyId(),
                        missingEntityOids);
            }
            // now execute the remaining batch of updates, if any
            if (commodityInsertStatements.size() > 0) {
                historydbIO.execute(BasedbIO.Style.FORCED, commodityInsertStatements);
            }
            Duration elapsed = Duration.between(start, Instant.now());
            logger.debug("Done persisting priceIndex info for context: {}, topology: {}, time {}",
                    topologyOrganizer.getTopologyContextId(), topologyOrganizer.getTopologyId(),
                    elapsed
            );
        } catch (VmtDbException e) {
            logger.warn("Error creating connection to persist PriceIndex information to DB", e);
        }
    }
}
