# suppress inspection "UnusedProperty" for whole file
identityGeneratorPrefix = 1
# This should be in sync with the schema in the Topology Processor s pom.xml
dbSchemaName = topology_processor
activateOrMoveInProgressRecordExpiredSeconds = 3600
moveSucceedRecordExpiredSeconds = 1800
activateSucceedRecordExpiredSeconds = 14400
# cloud probe discovery involves downloading some large files, so we are setting the discovery
# timeout to 120 seconds, instead of using the default of 30 seconds.
# several keep-alive messages are sent by the client during this interval to keep the connection
# open.
discoveryTimeoutSeconds = 120
validationTimeoutSeconds = 30
topologyBroadcastIntervalMinutes = 10
minimumAccountExpensesUploadIntervalMins = 60
minimumRIDataUploadIntervalMins = 5
actionTimeoutSeconds = 30
# Max number of concurrent target discoveries per probe.
maxConcurrentTargetDiscoveriesPerProbeCount = 5
# Urgent metrics are collected every 10 minutes, the offline every 3 days
collectionIntervalUrgentSec = 600
collectionIntervalOfflineSec = 259200
anonymized =  true
bridgeHost =  clustermgr
bridgePort = 8120
discoveredGroupUploadIntervalSeconds = 10
# The interval at which to attempt to reload assigned IDs
# after topology processor startup.
assignedIdReloadReattemptIntervalSeconds = 10
# This configuration value controls how often the commodity max values are
# loaded from history component = 3 Hours
maxValuesBackgroundLoadFrequencyMinutes = 180
# Timeout for acquiring the permit for running a discovering operation on a target.
probeDiscoveryPermitWaitTimeoutMins = 40
# Additional random interval timeout for acquring permit to prevent thundering
# herd issue.
probeDiscoveryPermitWaitTimeoutIntervalMins = 20
# This configuration value controls the initial delay before triggering
# the background load task when the initial load during startup fails.
# For subsequent fetches from the DB or when the initial load succeeds,
# the delay will be based on the maxValuesBackgroundLoadFrequencyMinutes
# config value.
maxValuesBackgroundLoadDelayOnInitFailureMinutes  = 30
# IOPS capacities for each type of disk in Storage Controller, Logical Pool,
# and Disk Array entities.
diskIopsCapacitySsd = 5000
diskIopsCapacity7200Rpm = 800
diskIopsCapacity10kRpm = 1200
diskIopsCapacity15kRpm = 1600
diskIopsCapacityVseriesLun = 5000
# Factor by which to multiply probe's estimate of array's IOPS capacity
# For probes like Pure and XtremIO which provide the StorageController
# and DiskArray estimated IOPS capacity directly rather than a disk count.
arrayIopsCapacityFactor = 1.0
# Factors by which to multiply IOPS Capacity if disk has certain properties
hybridDiskIopsFactor = 1.5
flashAvailableDiskIopsFactor = 1.3
# The interval hours that how long the new discovered entities can not be generated
# resize down actions by Market.
resizeDownWarmUpIntervalHours = 4
# Default timeout for async requests to topology processor.
asyncRestRequestTimeoutSeconds = 300
# Whether or not to periodically collect changes for random entities during stitching
# in the stitching journal. Use the journal-related parameters below to tune
# how much information is collected.
#
# Even if this parameter is turned to false the journal can be manually collected
# using the /topology-processor/stitchingJournal REST endpoint.
stitchingJournalEnabled = true
# Control parameters for tuning how frequently and how many entities we trace
# through the stitching journal. Tracking more changes in the journal introduces
# a greater performance hit but also provides greater debugging information.
# journalMaxChangesetsPerOperation controls the maximum number of changes to
# be entered in the journal for a single operation.
journalMaxChangesetsPerOperation = 100
# The number of entities that should be chronicled in the journal when we create
# a non-empty stitching journal. Setting to 0 produces a journal that tracks
# no changes.
journalNumEntitiesToRecord = 8
# In production, in order to ensure the stitching journal has minimal performance impact
# we usually create an empty journal that does not trace any changes. However, once
# in every journalsPerRecording, we create a non-empty journal that does trace changes
# according to the configurations above. So, for example, if journalsPerRecording is 6
# we will trace stitching changes in one of every 6 broadcasts.
#
# To manually trigger the stitching journal at run-time using configurations you
# can specify (permits custom journal filters and options), use the
# /topology-processor/stitchingJournal REST endpoint.
journalsPerRecording = 6
# Time, in hours that a cpu_model -> scale_factor mapping is cached.
scaleFactorCacheTimeoutHr = 8
